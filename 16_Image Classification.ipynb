{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第十六课 图片特征和图像分类\n",
    "\n",
    "- [ ] 载入clip模型并且抽取图片特征\n",
    "- [ ] 载入一个文件夹的图片进行抽取\n",
    "- [ ] 准备两个文件夹的图片\n",
    "- [ ] 训练分类器\n",
    "- [ ] 对新的图片进行分类测试\n",
    "- [ ] 搭建gradio的demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在之前的课程实践里我们做过一个很有趣的例子，就是准备两个文件夹的照片\n",
    "\n",
    "然后训练一个图像分类器，就可以对图像进行分类了。让我们在这里实践这个例子。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在计算机视觉课程中我们已经写过一个记录图片和对应标签的代码，\n",
    "\n",
    "让我们复习一下"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "\n",
    "{粘贴之前任意一个带手检测的程序}\n",
    "\n",
    "这段程序可以正常运行，我希望修改这段程序\n",
    "\n",
    "当按下任意非'q'键时，程序会在hand_record_data/hand_data.csv中(续写）记录手的所有关键点的坐标\n",
    "\n",
    "同时第一列记录按键对应的具体字幕\n",
    "\n",
    "同时把图片保存在hand_record_data/imgs中，命名规则为按键对应的具体字幕_时间戳.jpg\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import os\n",
    "import csv\n",
    "import time\n",
    "\n",
    "# 初始化MediaPipe手部模型\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(static_image_mode=False,\n",
    "                       max_num_hands=2,\n",
    "                       min_detection_confidence=0.5,\n",
    "                       min_tracking_confidence=0.5)\n",
    "\n",
    "# 获取绘图工具\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# 打开摄像头\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# 确保存储目录存在\n",
    "if not os.path.exists('hand_record_data/hand_data.csv'):\n",
    "    os.makedirs('hand_record_data/imgs', exist_ok=True)\n",
    "    with open('hand_record_data/hand_data.csv', 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        header = ['Key', 'Timestamp']\n",
    "        for i in range(21):  # Assuming max 21 landmarks per hand\n",
    "            header.extend([f'x{i}', f'y{i}', f'z{i}'])\n",
    "        writer.writerow(header)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        continue\n",
    "\n",
    "    # 左右翻转图像\n",
    "    frame = cv2.flip(frame, 1)\n",
    "\n",
    "    # 转换图像颜色空间从BGR到RGB\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    org_frame = frame.copy()\n",
    "\n",
    "    # 处理图像，检测手部\n",
    "    results = hands.process(frame_rgb)\n",
    "\n",
    "    # 绘制手部关键点\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "    # 显示图像\n",
    "    cv2.imshow('MediaPipe Hands with Mirror Image', frame)\n",
    "\n",
    "    # 检测按键输入\n",
    "    key = cv2.waitKey(5)\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "    elif key != -1:  # 任意其他有效按键\n",
    "        character = chr(key).lower()\n",
    "        timestamp = int(time.time())\n",
    "        image_name = f\"{character}_{timestamp}.jpg\"\n",
    "        image_path = f\"hand_record_data/imgs/{image_name}\"\n",
    "        cv2.imwrite(image_path, org_frame)  # 保存图像\n",
    "\n",
    "        # 记录数据\n",
    "        data = [character, timestamp]\n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                for lm in hand_landmarks.landmark:\n",
    "                    data.extend([lm.x, lm.y, lm.z])\n",
    "        # 保存到CSV文件\n",
    "        with open('hand_record_data/hand_data.csv', 'a', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(data)\n",
    "\n",
    "# 释放资源\n",
    "hands.close()\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同学们可以自己分别按下1，2，3来录制不同手势（比如石头、剪刀、布）的数据\n",
    "\n",
    "这个时候图片和imgs会分别保存到hand_record_data文件夹中\n",
    "\n",
    "这里李鲁鲁老师已经录制了一部分数据，同学们也可以下载hand_record_data.zip的压缩包进行解压\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在对应的imgs文件夹中就会有大量的石头剪刀布的图片\n",
    "\n",
    "这里石头的图片是以1_时间戳.jpg的形式命名的，以此类推，剪刀是2，布是3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HTTP_PROXY'] = 'http://localhost:8234'\n",
    "os.environ['HTTPS_PROXY'] = 'http://localhost:8234'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在上节课的时候，我们使用实现了src下面的ImageDatabase类\n",
    "\n",
    "我们可以用ImageDatabase(folder_name) 的方式，来初始化把一个文件夹下面的jpg文件都抽取成特征\n",
    "\n",
    "这个时候我们有两个办法来处理hand_record_data/imgs文件夹下面的图片\n",
    "\n",
    "- 修改ImageDatabase类，让它能够处理特性如1_*.jpg开头的图片\n",
    "- 不修改ImageDatabase类，然后手动把1_*.jpg开头的图片都复制到另一个文件夹，比如叫1_imgs，然后调用ImageDatabase('1_imgs')来处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里我们使用第二个方法，当然我们让ChatGPT来帮我们实现这一点"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "在hand_record_data/imgs文件夹下，有很多 1_xxx.jpg, 2_xxx.jpg, 3_xxx.jpg的图片\n",
    "\n",
    "我希望把1_xxx.jpg的图片都复制到hand_record_data/imgs_1文件夹下（新建这个文件夹）\n",
    "\n",
    "以此类推也处理2_xxx.jpg, 3_xxx.jpg的图片到对应的文件夹，请帮我实现一段python代码来处理这事情\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "def organize_images(src_folder, dst_folder_base):\n",
    "    # 获取源文件夹中的所有文件\n",
    "    files = os.listdir(src_folder)\n",
    "    \n",
    "    # 遍历文件，根据文件名进行分类\n",
    "    for file in files:\n",
    "        if file.endswith('.jpg'):\n",
    "            # 提取文件名中的数字部分，即分类的编号\n",
    "            category = file.split('_')[0]\n",
    "            # 构建目标文件夹路径\n",
    "            dst_folder = os.path.join(dst_folder_base, f'imgs_{category}')\n",
    "            # 如果目标文件夹不存在，则创建\n",
    "            if not os.path.exists(dst_folder):\n",
    "                os.makedirs(dst_folder)\n",
    "            # 复制文件到目标文件夹\n",
    "            shutil.copy(os.path.join(src_folder, file), os.path.join(dst_folder, file))\n",
    "\n",
    "# 源文件夹和目标文件夹的基础路径\n",
    "src_folder = 'hand_record_data/imgs'\n",
    "dst_folder_base = 'hand_record_data'\n",
    "\n",
    "# 调用函数执行操作\n",
    "organize_images(src_folder, dst_folder_base)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到运行完这段代码后，图片就被成功归类到三个文件夹了。这个时候我们可以调用ImageDatabase类来处理各个文件夹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python38\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "抽取文件夹1的特征完成\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "抽取文件夹2的特征完成\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "抽取文件夹3的特征完成\n"
     ]
    }
   ],
   "source": [
    "from src.ImageDatabase import ImageDatabase\n",
    "\n",
    "features = []\n",
    "\n",
    "for i in range(1, 4):\n",
    "    db = ImageDatabase(f'hand_record_data/imgs_{i}')\n",
    "    feature = db.get_all_features()\n",
    "    del db\n",
    "    # 删除db是为了防止占用过多内存\n",
    "    features.append(feature)\n",
    "    print(\"抽取文件夹{}的特征完成\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 768)\n",
      "(14, 768)\n",
      "(15, 768)\n"
     ]
    }
   ],
   "source": [
    "print(features[0].shape)\n",
    "print(features[1].shape)\n",
    "print(features[2].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里我们发现0，1，2都是三个numpy数组\n",
    "\n",
    "所以我们可以要求ChatGPT帮我们实现一个分类器，并且定义一个predict(feature, model)函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "features是一个list of numpy数组\n",
    "\n",
    "```python\n",
    "print(features[0].shape)\n",
    "print(features[1].shape)\n",
    "print(features[2].shape)\n",
    "```\n",
    "\n",
    "可以发现他们的shape分别为\n",
    "\n",
    "(16, 768)\n",
    "(14, 768)\n",
    "(15, 768)\n",
    "\n",
    "我希望实现一个随机森林的分类器，对features进行分类，把这个模型保存在hand_record_data/model.pkl\n",
    "\n",
    "并帮我实现对应的load函数，以及实现一个predict(feature, model) 函数，用来判断一个新的特征是哪个类别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型已保存并实现了加载和预测函数。\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# 假设 features 数据结构如下\n",
    "# features = [\n",
    "#     np.random.rand(16, 768),  # 示例数据\n",
    "#     np.random.rand(14, 768),  # 示例数据\n",
    "#     np.random.rand(15, 768)   # 示例数据\n",
    "# ]\n",
    "\n",
    "# 这里一定要注释掉，不然features被覆盖了！\n",
    "\n",
    "# 创建目标数组\n",
    "num_samples = [f.shape[0] for f in features]\n",
    "classes = np.concatenate([[i] * num_samples[i] for i in range(len(num_samples))])\n",
    "\n",
    "# 将 features 转换为一个单一的大数组\n",
    "features_concatenated = np.concatenate(features, axis=0)\n",
    "\n",
    "# 初始化并训练随机森林分类器\n",
    "rf_classifier = RandomForestClassifier()\n",
    "rf_classifier.fit(features_concatenated, classes)\n",
    "\n",
    "# 保存模型\n",
    "model_path = 'hand_record_data/model.pkl'\n",
    "if not os.path.exists('hand_record_data'):\n",
    "    os.makedirs('hand_record_data')\n",
    "with open(model_path, 'wb') as file:\n",
    "    pickle.dump(rf_classifier, file)\n",
    "\n",
    "# 实现加载模型的函数\n",
    "def load_model(path):\n",
    "    with open(path, 'rb') as file:\n",
    "        model = pickle.load(file)\n",
    "    return model\n",
    "\n",
    "# 实现预测函数\n",
    "def predict(feature, model):\n",
    "    return model.predict([feature])[0]\n",
    "\n",
    "# 输出信息\n",
    "print(\"模型已保存并实现了加载和预测函数。\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在我们就可以构建自己的分类器了\n",
    "\n",
    "完整的从图片到类别的过程要经历特征的抽取，然后再调用predict函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python38\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测结果为： 1 剪刀\n"
     ]
    }
   ],
   "source": [
    "from src.CLIPExtractor import CLIPExtractor\n",
    "cache_dir = \"D:\\\\aistudio\\\\LubaoGithub\\\\models\"\n",
    "clip_extractor = CLIPExtractor(model_name = \"openai/clip-vit-large-patch14\", cache_dir = cache_dir)\n",
    "\n",
    "# 保存模型\n",
    "model_path = 'hand_record_data/model.pkl'\n",
    "\n",
    "# 实现加载模型的函数\n",
    "def load_model(path):\n",
    "    with open(path, 'rb') as file:\n",
    "        model = pickle.load(file)\n",
    "    return model\n",
    "\n",
    "model = load_model(model_path)\n",
    "\n",
    "example_image = \"images/hand_test.jpg\"\n",
    "\n",
    "feature = clip_extractor.extract_image_from_file(example_image)\n",
    "\n",
    "prediction = predict(feature, model)\n",
    "\n",
    "texts = [\"石头\", \"剪刀\", \"布\"]\n",
    "\n",
    "print(\"预测结果为：\", prediction, texts[prediction ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们让ChatGPT为我们这段代码来建立一个gradio的demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{复制上面的代码}\n",
    "\n",
    "这段代码可以顺利运行\n",
    "\n",
    "我希望使用with gr.Blocks() as demo:的方式\n",
    "\n",
    "建立一个gradio的demo，这个gradio会接受一张图片（图片也可以从摄像头捕获）\n",
    "\n",
    "然后运行分类给出类别的判断"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python38\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import pickle\n",
    "from src.CLIPExtractor import CLIPExtractor\n",
    "\n",
    "# Initialize CLIP extractor\n",
    "cache_dir = \"D:\\\\aistudio\\\\LubaoGithub\\\\models\"\n",
    "clip_extractor = CLIPExtractor(model_name=\"openai/clip-vit-large-patch14\", cache_dir=cache_dir)\n",
    "\n",
    "# Load pre-trained model\n",
    "model_path = 'hand_record_data/model.pkl'\n",
    "\n",
    "def load_model(path):\n",
    "    with open(path, 'rb') as file:\n",
    "        model = pickle.load(file)\n",
    "    return model\n",
    "\n",
    "model = load_model(model_path)\n",
    "\n",
    "\n",
    "# 实现预测函数\n",
    "def predict(feature, model):\n",
    "    return model.predict([feature])[0]\n",
    "\n",
    "# Prediction function\n",
    "def predict_image(image):\n",
    "    # Extract features using CLIP extractor\n",
    "    feature = clip_extractor.extract_image(image)\n",
    "\n",
    "    # Make a prediction using the loaded model\n",
    "    prediction = model.predict(feature.reshape(1, -1))  # Assuming model is sklearn-based and accepts feature vector\n",
    "    texts = [\"石头\", \"剪刀\", \"布\"]\n",
    "    \n",
    "    return texts[prediction[0]]\n",
    "\n",
    "# Set up Gradio interface\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# Hand Gesture Recognition Demo\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            # image_input = gr.Image(source=\"upload\", tool=\"editor\", type=\"filepath\", label=\"Upload or Capture an Image\")\n",
    "            # webcam_input = gr.Image(source=\"webcam\", tool=\"editor\", type=\"filepath\", label=\"Capture from Webcam\")\n",
    "            image_input = gr.Image(label=\"上传图片\")\n",
    "\n",
    "        with gr.Column():\n",
    "            output_text = gr.Textbox(label=\"Prediction\", interactive=False)\n",
    "    \n",
    "    # Define action on button click\n",
    "    classify_button = gr.Button(\"Classify Image\")\n",
    "    classify_button.click(fn=predict_image, inputs=[image_input], outputs=[output_text])\n",
    "\n",
    "# Launch Gradio app\n",
    "demo.launch()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运行出来的效果就是这样的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Hand Classification Example](images/hand_classification.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 课堂练习\n",
    "\n",
    "- 寻找互联网上两类图片 比如鸡和鸭 进行分类的尝试\n",
    "- 其实训练过程（指定文件夹进行训练） 也可以用gradio来实现\n",
    "- 在这里我们尝试以深度学习模型的特征来进行分类，在计算机视觉课上我们说过手势点也可以作为特征，尝试用手的骨架识别点来作为特征进行分类尝试"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
