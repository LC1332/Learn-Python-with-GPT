{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第十五课 图片特征和图像搜索\n",
    "\n",
    "- [x] 载入clip模型并且抽取图片特征\n",
    "- [x] 实现一个拍照程序，方便给图片入库\n",
    "- [x] 使用特征进行以图搜图"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这节课中我们将尝试为图像抽取特征。\n",
    "\n",
    "在之前中我们尝试过分析特定的数据，比如泰坦尼克号乘客生存概率的数据\n",
    "\n",
    "或者在上一节课的作业中，有一个手势分类的例子\n",
    "\n",
    "这些特征是相对容易理解的。\n",
    "\n",
    "在这节课中，我们要接触另一类种类型的特征\n",
    "\n",
    "这些特征是深度学习发展起来之后，通过一个深度学习模型，在大量的数据集上训练得到的特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HTTP_PROXY'] = 'http://localhost:8234'\n",
    "os.environ['HTTPS_PROXY'] = 'http://localhost:8234'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果是在班级上课的话，我们这里建议老师们把模型拷贝给同学\n",
    "\n",
    "如果在家里上课的话，同学们直接设置cache_dir = None即可\n",
    "\n",
    "这样transformer库会自动下载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python38\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n"
     ]
    }
   ],
   "source": [
    "from src.CLIPExtractor import CLIPExtractor\n",
    "cache_dir = \"D:\\\\aistudio\\\\LubaoGithub\\\\models\"\n",
    "clip_extractor = CLIPExtractor(model_name = \"openai/clip-vit-large-patch14\", cache_dir = cache_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "openai/clip-vit-large-patch14 这个模型顾名思义是一个比较大的clip模型\n",
    "\n",
    "整体下载下来有1.5个G左右。如果同学老师们觉得这个模型太大，可以改为\n",
    "\n",
    "openai/clip-vit-base-patch32\n",
    "\n",
    "另外为了国内的同学老师下载方便，在ClipExtractor代码中，我们设置的https://hf-api.gitee.com这个镜像地址去下载。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来我们尝试用这个extractor的extract_image_from_file方法，来抽取一个图片的特征看看"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768,)\n",
      "[ 0.42208827 -0.33759007 -0.3351909  -0.6240947   0.44211075]\n"
     ]
    }
   ],
   "source": [
    "img_path = \"images/car.jpg\"\n",
    "\n",
    "feature = clip_extractor.extract_image_from_file(img_path)\n",
    "\n",
    "print(feature.shape)\n",
    "print(feature[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到CLIPExtractor输出了768个浮点数\n",
    "\n",
    "这些数字就是图像的“特征”\n",
    "\n",
    "当然这些特征很难用自然语言来描述。\n",
    "\n",
    "我们需要用“余弦相似度”来评估图片和图片之间的相似度。我们让ChatGPT来帮我们计算一下图片两两的相似度。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "img_path = \"images/car.jpg\"\n",
    "\n",
    "feature = clip_extractor.extract_image_from_file(img_path)\n",
    "\n",
    "print(feature.shape)\n",
    "print(feature[:5])\n",
    "```\n",
    "\n",
    "这段代码可以顺利运行，输出是\n",
    "\n",
    "```\n",
    "(768,)\n",
    "[ 0.42208827 -0.33759007 -0.3351909  -0.6240947   0.44211075]\n",
    "```\n",
    "\n",
    "在images文件夹下有 car.jpg, car2.jpg, 狗.jpg,  狐狸.jpg, 老虎.jpg, 骆驼.jpg\n",
    "\n",
    "参考上面这段代码，实现一段python程序，抽取每一张图片的特征，计算两两图片之间的相似度\n",
    "\n",
    "再在notebook中用一个表格对相似度进行可视化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 images/car.jpg  images/car2.jpg  images/狗.jpg  images/狐狸.jpg  \\\n",
      "images/car.jpg         1.000000         0.651916      0.527754       0.369409   \n",
      "images/car2.jpg        0.651916         1.000000      0.384417       0.252949   \n",
      "images/狗.jpg           0.527754         0.384417      1.000000       0.471594   \n",
      "images/狐狸.jpg          0.369409         0.252949      0.471594       1.000000   \n",
      "images/老虎.jpg          0.618884         0.430250      0.717786       0.538361   \n",
      "images/骆驼.jpg          0.570757         0.425792      0.624439       0.499466   \n",
      "\n",
      "                 images/老虎.jpg  images/骆驼.jpg  \n",
      "images/car.jpg        0.618884       0.570757  \n",
      "images/car2.jpg       0.430250       0.425792  \n",
      "images/狗.jpg          0.717786       0.624439  \n",
      "images/狐狸.jpg         0.538361       0.499466  \n",
      "images/老虎.jpg         1.000000       0.728275  \n",
      "images/骆驼.jpg         0.728275       1.000000  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Sample feature extraction function - replace with actual feature extraction logic\n",
    "def extract_image_feature(image_path):\n",
    "    # # Mockup feature extraction\n",
    "    # np.random.seed(hash(image_path) % 100000)  # To ensure reproducibility\n",
    "    # return np.random.randn(768)\n",
    "    return clip_extractor.extract_image_from_file(image_path)\n",
    "\n",
    "# List of image paths\n",
    "image_paths = [\"images/car.jpg\", \"images/car2.jpg\", \"images/狗.jpg\", \"images/狐狸.jpg\", \"images/老虎.jpg\", \"images/骆驼.jpg\"]\n",
    "\n",
    "# Extract features for each image\n",
    "features = {image_path: extract_image_feature(image_path) for image_path in image_paths}\n",
    "\n",
    "# Function to compute cosine similarity\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
    "\n",
    "# Calculate pairwise cosine similarities\n",
    "similarity_matrix = pd.DataFrame(index=image_paths, columns=image_paths, dtype=float)\n",
    "\n",
    "for img1 in image_paths:\n",
    "    for img2 in image_paths:\n",
    "        similarity_matrix.loc[img1, img2] = cosine_similarity(features[img1], features[img2])\n",
    "\n",
    "# Display the similarity matrix\n",
    "print(similarity_matrix)\n",
    "\n",
    "# import ace_tools as tools; tools.display_dataframe_to_user(name=\"Image Similarity Matrix\", dataframe=similarity_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到对于car.jpg来说，car2.jpg和他的相似度最高，达到了0.65\n",
    "\n",
    "当然狗和狐狸之间的相似度也很高，但是如果有另一张狗的图片，很有可能就是狗之间的相速度会更高了。\n",
    "\n",
    "所以我们可以用特征之间的余弦相似度，来制作最简单的以图搜图。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当然，在做这个以图搜图之前，让我们先完成一个“拍照”的程序"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我希望实现一个python的拍照程序\n",
    "\n",
    "- 按f键可以使得呈现的画面左右镜像\n",
    "\n",
    "- 按空格可以保存当前的图像，保存到record_images文件夹下，文件名为时间戳\n",
    "\n",
    "- 按q键可以退出程序\n",
    "\n",
    "如果程序开始的时候record_images文件夹不存在则新建一下。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "图片已保存：record_images/1724742614.jpg\n",
      "图片已保存：record_images/1724742632.jpg\n",
      "图片已保存：record_images/1724742637.jpg\n",
      "图片已保存：record_images/1724742649.jpg\n",
      "图片已保存：record_images/1724742660.jpg\n",
      "图片已保存：record_images/1724742672.jpg\n",
      "图片已保存：record_images/1724742681.jpg\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import time\n",
    "\n",
    "# 检查record_images文件夹是否存在，不存在则创建\n",
    "if not os.path.exists('record_images'):\n",
    "    os.makedirs('record_images')\n",
    "\n",
    "# 初始化摄像头\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# 设置镜像标志\n",
    "mirror = False\n",
    "\n",
    "while True:\n",
    "    # 从摄像头读取一帧\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        print(\"无法获取摄像头数据\")\n",
    "        break\n",
    "\n",
    "    # 如果mirror为True，则进行左右镜像操作\n",
    "    if mirror:\n",
    "        frame = cv2.flip(frame, 1)\n",
    "\n",
    "    # 显示画面\n",
    "    cv2.imshow('Camera', frame)\n",
    "\n",
    "    # 检查按键\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('f'):\n",
    "        # 切换镜像状态\n",
    "        mirror = not mirror\n",
    "    elif key == ord(' '):\n",
    "        # 保存图片\n",
    "        timestamp = int(time.time())\n",
    "        filename = f'record_images/{timestamp}.jpg'\n",
    "        cv2.imwrite(filename, frame)\n",
    "        print(f'图片已保存：{filename}')\n",
    "    elif key == ord('q'):\n",
    "        # 退出程序\n",
    "        break\n",
    "\n",
    "# 释放摄像头\n",
    "cap.release()\n",
    "# 关闭所有OpenCV窗口\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们在record_images里面已经存储了一些照片\n",
    "\n",
    "接下来我们要用clip_extractor提取这些照片的特征，并且最好存储起来\n",
    "\n",
    "以便于下次运行程序的时候，可以避免掉抽取的过程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from src.CLIPExtractor import CLIPExtractor\n",
    "\n",
    "clip_extractor = CLIPExtractor()\n",
    "\n",
    "img_path = \"images/car.jpg\"\n",
    "\n",
    "feature = clip_extractor.extract_image_from_file(img_path)\n",
    "\n",
    "print(feature.shape)\n",
    "print(feature[:5])\n",
    "```\n",
    "\n",
    "这段代码可以顺利抽取图片的特征，输出如下\n",
    "\n",
    "```\n",
    "(768,)\n",
    "[ 0.42208827 -0.33759007 -0.3351909  -0.6240947   0.44211075]\n",
    "```\n",
    "\n",
    "我希望建立一个类ImageDatabase，能够抽取record_images文件夹下所有jpg图片的特征，这个类包括下面的成员\n",
    "\n",
    "__init__( folder_name = \"record_images\" ) 进行初始化，\n",
    "\n",
    "这个类会先尝试读取folder_name下的feature.pkl文件，获取已经被抽取的文件和特征的关系\n",
    "\n",
    "接着扫描folder_name对应文件夹下的所有jpg图片，对于没有抽取过的图片，重新抽取特征\n",
    "\n",
    "然后将所有的文件和特征，重新存储到feature.pkl文件中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "c:\\Program Files\\Python38\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "为图片抽取特征并保存： 1724742614.jpg\n",
      "为图片抽取特征并保存： 1724742632.jpg\n",
      "为图片抽取特征并保存： 1724742637.jpg\n",
      "为图片抽取特征并保存： 1724742649.jpg\n",
      "为图片抽取特征并保存： 1724742660.jpg\n",
      "为图片抽取特征并保存： 1724742672.jpg\n",
      "为图片抽取特征并保存： 1724742681.jpg\n",
      "Features updated and saved.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "from src.CLIPExtractor import CLIPExtractor\n",
    "\n",
    "class ImageDatabase:\n",
    "    def __init__(self, folder_name=\"record_images\"):\n",
    "        self.folder_name = folder_name\n",
    "        self.feature_dict = self._load_features()\n",
    "\n",
    "        # 如果你有cache_dir的话，在这里指定，没有的话直接用 self.clip_extractor = CLIPExtractor() 初始化就可以。\n",
    "        cache_dir = \"D:\\\\aistudio\\\\LubaoGithub\\\\models\"\n",
    "        self.clip_extractor = CLIPExtractor(model_name = \"openai/clip-vit-large-patch14\", cache_dir = cache_dir)\n",
    "        self._update_features()\n",
    "\n",
    "    def _load_features(self):\n",
    "        # 尝试加载已保存的特征字典\n",
    "        feature_file = os.path.join(self.folder_name, \"feature.pkl\")\n",
    "        if os.path.exists(feature_file):\n",
    "            with open(feature_file, 'rb') as f:\n",
    "                return pickle.load(f)\n",
    "        else:\n",
    "            return {}\n",
    "\n",
    "    def _update_features(self):\n",
    "        # 遍历文件夹中的所有jpg图片\n",
    "        for filename in os.listdir(self.folder_name):\n",
    "            if filename.endswith(\".jpg\"):\n",
    "                img_path = os.path.join(self.folder_name, filename)\n",
    "                # 如果图片尚未被抽取特征，则进行特征抽取\n",
    "                if filename not in self.feature_dict:\n",
    "                    feature = self.clip_extractor.extract_image_from_file(img_path)\n",
    "                    self.feature_dict[filename] = feature\n",
    "                    print(\"为图片抽取特征并保存：\", filename)\n",
    "\n",
    "        # 保存更新后的特征字典\n",
    "        self._save_features()\n",
    "\n",
    "    def _save_features(self):\n",
    "        # 保存特征字典到文件\n",
    "        feature_file = os.path.join(self.folder_name, \"feature.pkl\")\n",
    "        with open(feature_file, 'wb') as f:\n",
    "            pickle.dump(self.feature_dict, f)\n",
    "\n",
    "# 使用示例\n",
    "database = ImageDatabase()\n",
    "print(\"Features updated and saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个时候对于一张新的照片比如images/search_example.jpg，我们肯定希望去抽取这个图片的特征，\n",
    "\n",
    "然后和ImageDatabase中的特征进行逐一比对，找到最相似的图片，并进行展示"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们先用之前的代码,尝试抽取images/search_example.jpg的特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768,)\n",
      "[ 0.7393415   0.52909625 -0.34023103 -0.08355319  0.38873   ]\n"
     ]
    }
   ],
   "source": [
    "img_path = \"images/search_example.jpg\"\n",
    "\n",
    "# 因为之前database中已经初始化过了CLIPExtractor，为了节省内存，这里直接用database.clip_extractor\n",
    "clip_extractor = database.clip_extractor\n",
    "\n",
    "feature = clip_extractor.extract_image_from_file(img_path)\n",
    "\n",
    "print(feature.shape)\n",
    "print(feature[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们接下来编辑一个prompt，为ImageDatabase增加一个search_with_feature( feature )方法，\n",
    "\n",
    "这个方法会返回输入特征最接近的图片以及对应的相似度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{复制ImageDatabase的代码，或者继续之前的对话}\n",
    "\n",
    "```python\n",
    "# Function to compute cosine similarity\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
    "```\n",
    "\n",
    "这个函数可以计算两个feature之间的相似度\n",
    "\n",
    "我希望为ImageDatabase增加一个成员函数 search_with_feature( feature )方法，\n",
    "\n",
    "输入query的特征，返回和输入特征最接近的图片的文件名，以及对应的相似度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "# 假设CLIPExtractor类和cosine_similarity函数已经定义\n",
    "from src.CLIPExtractor import CLIPExtractor\n",
    "\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
    "\n",
    "class ImageDatabase:\n",
    "    def __init__(self, folder_name=\"record_images\"):\n",
    "        self.folder_name = folder_name\n",
    "        self.feature_dict = self._load_features()\n",
    "        # 如果你有cache_dir的话，在这里指定，没有的话直接用 self.clip_extractor = CLIPExtractor() 初始化就可以。\n",
    "        cache_dir = \"D:\\\\aistudio\\\\LubaoGithub\\\\models\"\n",
    "        self.clip_extractor = CLIPExtractor(model_name = \"openai/clip-vit-large-patch14\", cache_dir = cache_dir)\n",
    "        self._update_features()\n",
    "\n",
    "    def _load_features(self):\n",
    "        feature_file = os.path.join(self.folder_name, \"feature.pkl\")\n",
    "        if os.path.exists(feature_file):\n",
    "            with open(feature_file, 'rb') as f:\n",
    "                return pickle.load(f)\n",
    "        else:\n",
    "            return {}\n",
    "\n",
    "    def _update_features(self):\n",
    "        for filename in os.listdir(self.folder_name):\n",
    "            if filename.endswith(\".jpg\"):\n",
    "                img_path = os.path.join(self.folder_name, filename)\n",
    "                if filename not in self.feature_dict:\n",
    "                    feature = self.clip_extractor.extract_image_from_file(img_path)\n",
    "                    self.feature_dict[filename] = feature\n",
    "        self._save_features()\n",
    "\n",
    "    def _save_features(self):\n",
    "        feature_file = os.path.join(self.folder_name, \"feature.pkl\")\n",
    "        with open(feature_file, 'wb') as f:\n",
    "            pickle.dump(self.feature_dict, f)\n",
    "\n",
    "    def search_with_feature(self, query_feature):\n",
    "        max_similarity = -1\n",
    "        most_similar_image = None\n",
    "\n",
    "        for filename, feature in self.feature_dict.items():\n",
    "            similarity = cosine_similarity(query_feature, feature)\n",
    "            if similarity > max_similarity:\n",
    "                max_similarity = similarity\n",
    "                most_similar_image = filename\n",
    "\n",
    "        return most_similar_image, max_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面我们来实现测试代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1724742672.jpg\n",
      "1.0000001\n"
     ]
    }
   ],
   "source": [
    "database = ImageDatabase()\n",
    "\n",
    "img_path = \"images/search_example.jpg\"\n",
    "\n",
    "# 因为之前database中已经初始化过了CLIPExtractor，为了节省内存，这里直接用database.clip_extractor\n",
    "clip_extractor = database.clip_extractor\n",
    "\n",
    "query_feature = clip_extractor.extract_image_from_file(img_path)\n",
    "\n",
    "most_similar_image, max_similarity = database.search_with_feature(query_feature)\n",
    "\n",
    "print(most_similar_image)\n",
    "print(max_similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到这段程序是可以正常输出的\n",
    "\n",
    "当然这样做太抽象了，我们需要实现一个实时的程序来进行可视化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "database = ImageDatabase()\n",
    "\n",
    "img_path = \"images/search_example.jpg\"\n",
    "\n",
    "# 因为之前database中已经初始化过了CLIPExtractor，为了节省内存，这里直接用database.clip_extractor\n",
    "clip_extractor = database.clip_extractor\n",
    "\n",
    "query_feature = clip_extractor.extract_image_from_file(img_path)\n",
    "\n",
    "most_similar_image, max_similarity = database.search_with_feature(query_feature)\n",
    "\n",
    "print(most_similar_image)\n",
    "print(max_similarity)\n",
    "```\n",
    "\n",
    "这段代码可以顺利运行\n",
    "\n",
    "clip_extractor还有一个方法extract_image( frame )可以直接抽取frame中的特征\n",
    "\n",
    "我希望实现一个摄像头程序\n",
    "\n",
    "一开始的时候初始化一张全黑的图片，放在摄像头原图的右边\n",
    "\n",
    "然后摄像头不断读取图片，并抽取特征，然后和数据库中的特征进行比对，找到最相似的图片，然后显示在摄像头原图的右边\n",
    "\n",
    "整个程序支持按f翻转镜头，或者按空格记录图片 以及按q退出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python38\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from src.CLIPExtractor import CLIPExtractor\n",
    "\n",
    "# from image_database import ImageDatabase  # 假设之前的ImageDatabase类被保存在image_database.py文件中\n",
    "from src.ImageDatabase import ImageDatabase\n",
    "\n",
    "# 初始化数据库\n",
    "database = ImageDatabase()\n",
    "\n",
    "# 初始化CLIPExtractor\n",
    "clip_extractor = database.clip_extractor\n",
    "\n",
    "# 初始化摄像头\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# 初始化全黑图片\n",
    "black_image = np.zeros((480, 640, 3), dtype=np.uint8)\n",
    "\n",
    "# 检查摄像头是否打开\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video.\")\n",
    "    exit()\n",
    "\n",
    "while True:\n",
    "    # 读取摄像头帧\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Error: Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "\n",
    "    # 抽取摄像头帧的特征\n",
    "    frame_feature = clip_extractor.extract_image(frame)\n",
    "\n",
    "    # 使用抽取的特征在数据库中搜索最相似的图片\n",
    "    most_similar_image, max_similarity = database.search_with_feature(frame_feature)\n",
    "\n",
    "    # 加载最相似的图片\n",
    "    if most_similar_image:\n",
    "        similar_image = cv2.imread(os.path.join(database.folder_name, most_similar_image))\n",
    "        if similar_image is not None:\n",
    "            # 将摄像头帧和最相似的图片并排显示\n",
    "            combined_image = cv2.hconcat([frame, similar_image])\n",
    "        else:\n",
    "            combined_image = cv2.hconcat([frame, black_image])\n",
    "    else:\n",
    "        combined_image = cv2.hconcat([frame, black_image])\n",
    "\n",
    "    # 显示组合后的图片\n",
    "    cv2.imshow('Camera + Most Similar Image', combined_image)\n",
    "\n",
    "    # 处理按键事件\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "    elif key == ord('f'):\n",
    "        # 翻转摄像头帧\n",
    "        frame = cv2.flip(frame, 1)\n",
    "    elif key == ord(' '):\n",
    "        # 保存当前帧到数据库\n",
    "        filename = f\"recorded_{int(cv2.getTickCount())}.jpg\"\n",
    "        cv2.imwrite(os.path.join(database.folder_name, filename), frame)\n",
    "        feature = clip_extractor.extract_image(frame)\n",
    "        database.feature_dict[filename] = feature\n",
    "        database._save_features()\n",
    "\n",
    "# 释放摄像头和销毁所有窗口\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到这段程序可以正常运行\n",
    "\n",
    "但是非常卡顿，这是由于frame_feature = clip_extractor.extract_image(frame)这句语句非常消耗时间\n",
    "\n",
    "这个时候我们可以要求chatgpt把程序修改为多线程的程序"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "{复制之前的程序，或者在之前的连续会话中}\n",
    "\n",
    "这段程序可以正常运行，但是frame_feature = clip_extractor.extract_image(frame)这句话非常消耗时间\n",
    "\n",
    "我希望修改这段程序，使得画面的左边始终流畅显示frame，\n",
    "\n",
    "但是同时在另一个线程，如果没有当前抽取的frame，则把frame送去抽取，如果抽取结束，则存储抽取完的feature到last_feature 然后把待抽取的frame更新成None然\n",
    "\n",
    "并且对最近抽取的特征last_feature，搜索最相近的照片在右侧显示\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import threading\n",
    "from src.CLIPExtractor import CLIPExtractor\n",
    "from src.ImageDatabase import ImageDatabase\n",
    "\n",
    "# Initialize the database\n",
    "database = ImageDatabase()\n",
    "\n",
    "# Initialize CLIPExtractor\n",
    "clip_extractor = database.clip_extractor\n",
    "\n",
    "# Initialize the camera\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Initialize a full black image\n",
    "black_image = np.zeros((480, 640, 3), dtype=np.uint8)\n",
    "\n",
    "# Check if the camera opened correctly\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video.\")\n",
    "    exit()\n",
    "\n",
    "# Variables for threading\n",
    "frame_to_extract = None\n",
    "last_feature = None\n",
    "lock = threading.Lock()\n",
    "\n",
    "def feature_extraction_thread():\n",
    "    global frame_to_extract, last_feature\n",
    "    while True:\n",
    "        if frame_to_extract is not None:\n",
    "            # Extract feature for the current frame\n",
    "            feature = clip_extractor.extract_image(frame_to_extract)\n",
    "\n",
    "            # Store the extracted feature\n",
    "            with lock:\n",
    "                last_feature = feature\n",
    "                frame_to_extract = None\n",
    "\n",
    "# Start the feature extraction thread\n",
    "threading.Thread(target=feature_extraction_thread, daemon=True).start()\n",
    "\n",
    "while True:\n",
    "    # Read camera frame\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Error: Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "\n",
    "    # Display the camera frame smoothly\n",
    "    combined_image = cv2.hconcat([frame, black_image])\n",
    "\n",
    "    # Search for the most similar image using the last extracted feature\n",
    "    if last_feature is not None:\n",
    "        most_similar_image, max_similarity = database.search_with_feature(last_feature)\n",
    "        if most_similar_image:\n",
    "            similar_image = cv2.imread(os.path.join(database.folder_name, most_similar_image))\n",
    "            if similar_image is not None:\n",
    "                # Display the frame and the most similar image side by side\n",
    "                combined_image = cv2.hconcat([frame, similar_image])\n",
    "        else:\n",
    "            combined_image = cv2.hconcat([frame, black_image])\n",
    "\n",
    "    # Show the combined image\n",
    "    cv2.imshow('Camera + Most Similar Image', combined_image)\n",
    "\n",
    "    # Handle key events\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "    elif key == ord('f'):\n",
    "        # Flip the camera frame\n",
    "        frame = cv2.flip(frame, 1)\n",
    "    elif key == ord(' '):\n",
    "        # Save the current frame to the database\n",
    "        filename = f\"recorded_{int(cv2.getTickCount())}.jpg\"\n",
    "        cv2.imwrite(os.path.join(database.folder_name, filename), frame)\n",
    "        feature = clip_extractor.extract_image(frame)\n",
    "        database.feature_dict[filename] = feature\n",
    "        database._save_features()\n",
    "\n",
    "    # Assign frame for feature extraction in a separate thread\n",
    "    if frame_to_extract is None:\n",
    "        with lock:\n",
    "            frame_to_extract = frame.copy()\n",
    "\n",
    "# Release the camera and destroy all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "暂时调通了这个例子，但是还是比较难的\n",
    "\n",
    "这节课后面就不上分类了，先把这个图像搜索上完就可以，下节课上分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
